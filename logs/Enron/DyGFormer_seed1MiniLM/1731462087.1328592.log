hit@102024-11-13 01:41:27,148 - root - INFO - ********** Run 2 starts. **********
2024-11-13 01:41:27,148 - root - INFO - configuration is Namespace(batch_size=256, channel_embedding_dim=50, code_path='.', dataset_name='Enron', device='cuda:0', dropout=0.1, edge_bank_memory_mode='unlimited_memory', gpu=0, learning_rate=0.0001, load_best_configs=True, max_input_sequence_length=32, model_name='DyGFormer', negative_sample_strategy='random', num_epochs=50, num_heads=2, num_layers=2, num_neighbors=20, num_runs=3, num_walk_heads=8, optimizer='Adam', patch_size=1, patience=5, position_feat_dim=384, sample_neighbor_strategy='recent', save_model_name='DyGFormer_seed1MiniLM', seed=1, temporal_chain_length=10, test_interval_epochs=10, test_ratio=0.2, time_dim=384, time_feat_dim=100, time_gap=2000, time_scaling_factor=1e-06, time_window_mode='fixed_proportion', train_LM='', use_feature='MiniLM', val_ratio=0.2, walk_length=1, weight_decay=0.0)
2024-11-13 01:41:27,148 - root - INFO - node feature size (42712, 384)
2024-11-13 01:41:27,148 - root - INFO - edge feature size (77831, 384)
2024-11-13 01:41:27,149 - root - INFO - node feature example [-0.05771908  0.03367884  0.02701225  0.04685534 -0.08852572]
2024-11-13 01:41:27,149 - root - INFO - edge feature example [ 0.01366738 -0.09950824  0.01774721  0.02573822 -0.033234  ]
2024-11-13 01:41:27,370 - root - INFO - model -> Sequential(
  (0): DyGFormer(
    (temporal_chain): TemporalChain()
    (time_encoder): TimeEncoder(
      (w): Linear(in_features=1, out_features=100, bias=True)
    )
    (neighbor_co_occurrence_encoder): NeighborCooccurrenceEncoder(
      (neighbor_co_occurrence_encode_layer): Sequential(
        (0): Linear(in_features=1, out_features=50, bias=True)
        (1): ReLU()
        (2): Linear(in_features=50, out_features=50, bias=True)
      )
    )
    (projection_layer): ModuleDict(
      (node): Linear(in_features=384, out_features=50, bias=True)
      (edge): Linear(in_features=384, out_features=50, bias=True)
      (time): Linear(in_features=100, out_features=50, bias=True)
      (neighbor_co_occurrence): Linear(in_features=50, out_features=50, bias=True)
      (temporal_chain): Linear(in_features=484, out_features=200, bias=True)
    )
    (transformers): ModuleList(
      (0-1): 2 x TransformerEncoder(
        (multi_head_attention): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)
        )
        (dropout): Dropout(p=0.1, inplace=False)
        (linear_layers): ModuleList(
          (0): Linear(in_features=200, out_features=800, bias=True)
          (1): Linear(in_features=800, out_features=200, bias=True)
        )
        (norm_layers): ModuleList(
          (0-1): 2 x LayerNorm((200,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (temporal_chain_encoder): TemporalChainEncoder(
      (multi_head_attention): MultiheadAttention(
        (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)
      )
      (dropout): Dropout(p=0.1, inplace=False)
      (linear_layers): ModuleList(
        (0): Linear(in_features=200, out_features=400, bias=True)
        (1): Linear(in_features=400, out_features=200, bias=True)
      )
      (norm_layers): ModuleList(
        (0-1): 2 x LayerNorm((200,), eps=1e-05, elementwise_affine=True)
      )
    )
    (temporal_chain_fusion_layer): RawTemporalChainFusion4DyGFormer(
      (fusion_layer): MergeLayer(
        (fc1): Linear(in_features=400, out_features=400, bias=True)
        (fc2): Linear(in_features=400, out_features=400, bias=True)
        (act): ReLU()
      )
      (layer_norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (output_layer): ModuleDict(
      (graph_modal): Linear(in_features=200, out_features=384, bias=True)
      (text_modal): Linear(in_features=200, out_features=384, bias=True)
    )
    (merge_layer): MergeLayer(
      (fc1): Linear(in_features=1168, out_features=384, bias=True)
      (fc2): Linear(in_features=384, out_features=384, bias=True)
      (act): ReLU()
    )
  )
  (1): MergeLayer(
    (fc1): Linear(in_features=768, out_features=384, bias=True)
    (fc2): Linear(in_features=384, out_features=1, bias=True)
    (act): ReLU()
  )
)
2024-11-13 01:41:27,371 - root - INFO - model name: DyGFormer, #parameters: 11205340 B, 10942.71484375 KB, 10.68624496459961 MB.
2024-11-13 01:43:53,505 - root - INFO - Epoch: 1, train for the 500-th batch, train loss: 0.2507777512073517
2024-11-13 01:46:24,268 - root - INFO - Epoch: 1, train for the 1000-th batch, train loss: 0.15932400524616241
2024-11-13 01:49:44,055 - root - INFO - Epoch: 2, train for the 500-th batch, train loss: 0.18371376395225525
2024-11-13 01:52:15,250 - root - INFO - Epoch: 2, train for the 1000-th batch, train loss: 0.11470292508602142
2024-11-13 01:55:36,494 - root - INFO - Epoch: 3, train for the 500-th batch, train loss: 0.18861964344978333
2024-11-13 01:58:08,802 - root - INFO - Epoch: 3, train for the 1000-th batch, train loss: 0.10978642851114273
2024-11-13 02:01:30,176 - root - INFO - Epoch: 4, train for the 500-th batch, train loss: 0.17297080159187317
2024-11-13 02:04:02,438 - root - INFO - Epoch: 4, train for the 1000-th batch, train loss: 0.13035759329795837
2024-11-13 02:07:24,061 - root - INFO - Epoch: 5, train for the 500-th batch, train loss: 0.14713121950626373
2024-11-13 02:09:56,946 - root - INFO - Epoch: 5, train for the 1000-th batch, train loss: 0.10873065888881683
2024-11-13 02:14:46,873 - root - INFO - Epoch: 5, learning rate: 0.0001, train loss: 0.1980
2024-11-13 02:14:46,877 - root - INFO - train average_precision, 0.9742
2024-11-13 02:14:46,877 - root - INFO - train roc_auc, 0.9720
2024-11-13 02:14:46,878 - root - INFO - train MRR, 0.7768
2024-11-13 02:14:46,878 - root - INFO - train NDGC@3, 0.9989
2024-11-13 02:14:46,878 - root - INFO - train hit@10, 0.8417
2024-11-13 02:14:46,879 - root - INFO - validate loss: 0.1750
2024-11-13 02:14:46,879 - root - INFO - validate average_precision, 0.9837
2024-11-13 02:14:46,879 - root - INFO - validate roc_auc, 0.9821
2024-11-13 02:14:46,879 - root - INFO - validate MRR, 0.8296
2024-11-13 02:14:46,879 - root - INFO - validate NDGC@3, 0.9993
2024-11-13 02:14:46,880 - root - INFO - validate hit@10, 0.8898
2024-11-13 02:14:46,880 - root - INFO - new node validate loss: 0.3301
2024-11-13 02:14:46,880 - root - INFO - new node validate average_precision, 0.9593
2024-11-13 02:14:46,880 - root - INFO - new node validate roc_auc, 0.9550
2024-11-13 02:14:46,880 - root - INFO - new node validate MRR, 0.6891
2024-11-13 02:14:46,880 - root - INFO - new node validate NDGC@3, 0.9962
2024-11-13 02:14:46,880 - root - INFO - new node validate hit@10, 0.7792
2024-11-13 02:14:46,881 - root - INFO - save model ./saved_models/DyGFormer/Enron/DyGFormer_seed1MiniLM/DyGFormer_seed1MiniLM_1731462087.pkl
2024-11-13 02:17:15,093 - root - INFO - Epoch: 6, train for the 500-th batch, train loss: 0.15757638216018677
2024-11-13 02:19:47,478 - root - INFO - Epoch: 6, train for the 1000-th batch, train loss: 0.09449948370456696
2024-11-13 02:23:09,528 - root - INFO - Epoch: 7, train for the 500-th batch, train loss: 0.17455747723579407
2024-11-13 02:25:40,238 - root - INFO - Epoch: 7, train for the 1000-th batch, train loss: 0.12361779063940048
2024-11-13 02:29:01,524 - root - INFO - Epoch: 8, train for the 500-th batch, train loss: 0.14932703971862793
2024-11-13 02:31:33,649 - root - INFO - Epoch: 8, train for the 1000-th batch, train loss: 0.11847000569105148
2024-11-13 02:34:54,414 - root - INFO - Epoch: 9, train for the 500-th batch, train loss: 0.13341201841831207
2024-11-13 02:37:25,943 - root - INFO - Epoch: 9, train for the 1000-th batch, train loss: 0.103803351521492
2024-11-13 02:40:46,155 - root - INFO - Epoch: 10, train for the 500-th batch, train loss: 0.16289347410202026
2024-11-13 02:43:18,311 - root - INFO - Epoch: 10, train for the 1000-th batch, train loss: 0.11653462052345276
2024-11-13 02:48:04,806 - root - INFO - Epoch: 10, learning rate: 0.0001, train loss: 0.1804
2024-11-13 02:48:04,807 - root - INFO - train average_precision, 0.9780
2024-11-13 02:48:04,807 - root - INFO - train roc_auc, 0.9766
2024-11-13 02:48:04,808 - root - INFO - train MRR, 0.7928
2024-11-13 02:48:04,808 - root - INFO - train NDGC@3, 0.9991
2024-11-13 02:48:04,808 - root - INFO - train hit@10, 0.8592
2024-11-13 02:48:04,808 - root - INFO - validate loss: 0.1571
2024-11-13 02:48:04,809 - root - INFO - validate average_precision, 0.9857
2024-11-13 02:48:04,809 - root - INFO - validate roc_auc, 0.9852
2024-11-13 02:48:04,809 - root - INFO - validate MRR, 0.8270
2024-11-13 02:48:04,809 - root - INFO - validate NDGC@3, 1.0000
2024-11-13 02:48:04,809 - root - INFO - validate hit@10, 0.8920
2024-11-13 02:48:04,810 - root - INFO - new node validate loss: 0.3163
2024-11-13 02:48:04,810 - root - INFO - new node validate average_precision, 0.9599
2024-11-13 02:48:04,810 - root - INFO - new node validate roc_auc, 0.9569
2024-11-13 02:48:04,810 - root - INFO - new node validate MRR, 0.6782
2024-11-13 02:48:04,810 - root - INFO - new node validate NDGC@3, 0.9956
2024-11-13 02:48:04,810 - root - INFO - new node validate hit@10, 0.7668
2024-11-13 02:52:02,142 - root - INFO - test loss: 0.1613
2024-11-13 02:52:02,142 - root - INFO - test average_precision, 0.9851
2024-11-13 02:52:02,143 - root - INFO - test roc_auc, 0.9850
2024-11-13 02:52:02,143 - root - INFO - test MRR, 0.8174
2024-11-13 02:52:02,143 - root - INFO - test NDGC@3, 0.9996
2024-11-13 02:52:02,143 - root - INFO - test hit@10, 0.8810
2024-11-13 02:52:02,143 - root - INFO - new node test loss: 0.2778
2024-11-13 02:52:02,144 - root - INFO - new node test average_precision, 0.9618
2024-11-13 02:52:02,144 - root - INFO - new node test roc_auc, 0.9588
2024-11-13 02:52:02,144 - root - INFO - new node test MRR, 0.6866
2024-11-13 02:52:02,144 - root - INFO - new node test NDGC@3, 0.9983
2024-11-13 02:52:02,144 - root - INFO - new node test hit@10, 0.7664
2024-11-13 02:54:32,582 - root - INFO - Epoch: 11, train for the 500-th batch, train loss: 0.15938344597816467
2024-11-13 02:57:07,500 - root - INFO - Epoch: 11, train for the 1000-th batch, train loss: 0.08616180717945099
2024-11-13 03:00:28,998 - root - INFO - Epoch: 12, train for the 500-th batch, train loss: 0.14941465854644775
2024-11-13 03:03:00,476 - root - INFO - Epoch: 12, train for the 1000-th batch, train loss: 0.08640454709529877
2024-11-13 03:07:14,370 - root - INFO - Epoch: 13, train for the 500-th batch, train loss: 0.14663714170455933
2024-11-13 03:10:59,093 - root - INFO - Epoch: 13, train for the 1000-th batch, train loss: 0.08862528949975967
2024-11-13 03:16:04,306 - root - INFO - Epoch: 14, train for the 500-th batch, train loss: 0.1499028503894806
2024-11-13 03:19:47,622 - root - INFO - Epoch: 14, train for the 1000-th batch, train loss: 0.09772609919309616
2024-11-13 03:24:43,167 - root - INFO - Epoch: 15, train for the 500-th batch, train loss: 0.15148600935935974
2024-11-13 03:28:26,520 - root - INFO - Epoch: 15, train for the 1000-th batch, train loss: 0.10608279705047607
2024-11-13 03:35:50,981 - root - INFO - Epoch: 15, learning rate: 0.0001, train loss: 0.1675
2024-11-13 03:35:50,987 - root - INFO - train average_precision, 0.9810
2024-11-13 03:35:50,987 - root - INFO - train roc_auc, 0.9802
2024-11-13 03:35:50,988 - root - INFO - train MRR, 0.8037
2024-11-13 03:35:50,988 - root - INFO - train NDGC@3, 0.9993
2024-11-13 03:35:50,989 - root - INFO - train hit@10, 0.8698
2024-11-13 03:35:50,989 - root - INFO - validate loss: 0.1422
2024-11-13 03:35:50,989 - root - INFO - validate average_precision, 0.9877
2024-11-13 03:35:50,989 - root - INFO - validate roc_auc, 0.9874
2024-11-13 03:35:50,990 - root - INFO - validate MRR, 0.8337
2024-11-13 03:35:50,990 - root - INFO - validate NDGC@3, 0.9993
2024-11-13 03:35:50,990 - root - INFO - validate hit@10, 0.8996
2024-11-13 03:35:50,990 - root - INFO - new node validate loss: 0.3087
2024-11-13 03:35:50,990 - root - INFO - new node validate average_precision, 0.9586
2024-11-13 03:35:50,990 - root - INFO - new node validate roc_auc, 0.9570
2024-11-13 03:35:50,990 - root - INFO - new node validate MRR, 0.6595
2024-11-13 03:35:50,991 - root - INFO - new node validate NDGC@3, 0.9918
2024-11-13 03:35:50,991 - root - INFO - new node validate hit@10, 0.7490
2024-11-13 03:35:50,991 - root - INFO - save model ./saved_models/DyGFormer/Enron/DyGFormer_seed1MiniLM/DyGFormer_seed1MiniLM_1731462087.pkl
2024-11-13 03:39:33,846 - root - INFO - Epoch: 16, train for the 500-th batch, train loss: 0.13886244595050812
2024-11-13 03:43:21,466 - root - INFO - Epoch: 16, train for the 1000-th batch, train loss: 0.0732324868440628
2024-11-13 03:48:17,283 - root - INFO - Epoch: 17, train for the 500-th batch, train loss: 0.1280752718448639
2024-11-13 03:52:03,380 - root - INFO - Epoch: 17, train for the 1000-th batch, train loss: 0.08749406039714813
2024-11-13 03:57:03,924 - root - INFO - Epoch: 18, train for the 500-th batch, train loss: 0.12593255937099457
2024-11-13 04:00:29,870 - root - INFO - Epoch: 18, train for the 1000-th batch, train loss: 0.06894896924495697
2024-11-13 04:05:49,311 - root - INFO - Epoch: 19, train for the 500-th batch, train loss: 0.11243195831775665
2024-11-13 04:09:40,722 - root - INFO - Epoch: 19, train for the 1000-th batch, train loss: 0.10081005096435547
2024-11-13 04:15:01,506 - root - INFO - Epoch: 20, train for the 500-th batch, train loss: 0.11118560284376144
2024-11-13 04:19:02,722 - root - INFO - Epoch: 20, train for the 1000-th batch, train loss: 0.050994835793972015
2024-11-13 04:26:59,636 - root - INFO - Epoch: 20, learning rate: 0.0001, train loss: 0.1532
2024-11-13 04:26:59,637 - root - INFO - train average_precision, 0.9840
2024-11-13 04:26:59,637 - root - INFO - train roc_auc, 0.9837
2024-11-13 04:26:59,638 - root - INFO - train MRR, 0.8226
2024-11-13 04:26:59,638 - root - INFO - train NDGC@3, 0.9988
2024-11-13 04:26:59,638 - root - INFO - train hit@10, 0.8864
2024-11-13 04:26:59,638 - root - INFO - validate loss: 0.1395
2024-11-13 04:26:59,639 - root - INFO - validate average_precision, 0.9894
2024-11-13 04:26:59,639 - root - INFO - validate roc_auc, 0.9887
2024-11-13 04:26:59,639 - root - INFO - validate MRR, 0.8666
2024-11-13 04:26:59,639 - root - INFO - validate NDGC@3, 1.0000
2024-11-13 04:26:59,639 - root - INFO - validate hit@10, 0.9149
2024-11-13 04:26:59,640 - root - INFO - new node validate loss: 0.2960
2024-11-13 04:26:59,640 - root - INFO - new node validate average_precision, 0.9625
2024-11-13 04:26:59,640 - root - INFO - new node validate roc_auc, 0.9594
2024-11-13 04:26:59,640 - root - INFO - new node validate MRR, 0.7057
2024-11-13 04:26:59,640 - root - INFO - new node validate NDGC@3, 0.9956
2024-11-13 04:26:59,640 - root - INFO - new node validate hit@10, 0.7847
2024-11-13 04:26:59,641 - root - INFO - save model ./saved_models/DyGFormer/Enron/DyGFormer_seed1MiniLM/DyGFormer_seed1MiniLM_1731462087.pkl
2024-11-13 04:33:30,190 - root - INFO - test loss: 0.1748
2024-11-13 04:33:30,191 - root - INFO - test average_precision, 0.9879
2024-11-13 04:33:30,191 - root - INFO - test roc_auc, 0.9875
2024-11-13 04:33:30,192 - root - INFO - test MRR, 0.8435
2024-11-13 04:33:30,192 - root - INFO - test NDGC@3, 1.0000
2024-11-13 04:33:30,192 - root - INFO - test hit@10, 0.8995
2024-11-13 04:33:30,192 - root - INFO - new node test loss: 0.2845
2024-11-13 04:33:30,192 - root - INFO - new node test average_precision, 0.9665
2024-11-13 04:33:30,193 - root - INFO - new node test roc_auc, 0.9643
2024-11-13 04:33:30,193 - root - INFO - new node test MRR, 0.7159
2024-11-13 04:33:30,193 - root - INFO - new node test NDGC@3, 0.9975
2024-11-13 04:33:30,193 - root - INFO - new node test hit@10, 0.7905
2024-11-13 04:37:16,960 - root - INFO - Epoch: 21, train for the 500-th batch, train loss: 0.11834363639354706
2024-11-13 04:41:07,584 - root - INFO - Epoch: 21, train for the 1000-th batch, train loss: 0.06166170537471771
2024-11-13 04:46:14,384 - root - INFO - Epoch: 22, train for the 500-th batch, train loss: 0.1521119475364685
2024-11-13 04:50:10,415 - root - INFO - Epoch: 22, train for the 1000-th batch, train loss: 0.060221683233976364
2024-11-13 04:55:22,508 - root - INFO - Epoch: 23, train for the 500-th batch, train loss: 0.08454235643148422
2024-11-13 04:59:15,217 - root - INFO - Epoch: 23, train for the 1000-th batch, train loss: 0.04618688300251961
2024-11-13 05:04:21,738 - root - INFO - Epoch: 24, train for the 500-th batch, train loss: 0.11309593915939331
2024-11-13 05:08:25,338 - root - INFO - Epoch: 24, train for the 1000-th batch, train loss: 0.06297286599874496
2024-11-13 05:13:32,754 - root - INFO - Epoch: 25, train for the 500-th batch, train loss: 0.12796220183372498
2024-11-13 05:17:22,597 - root - INFO - Epoch: 25, train for the 1000-th batch, train loss: 0.03000357560813427
2024-11-13 05:25:06,308 - root - INFO - Epoch: 25, learning rate: 0.0001, train loss: 0.1419
2024-11-13 05:25:06,309 - root - INFO - train average_precision, 0.9852
2024-11-13 05:25:06,309 - root - INFO - train roc_auc, 0.9851
2024-11-13 05:25:06,310 - root - INFO - train MRR, 0.8355
2024-11-13 05:25:06,310 - root - INFO - train NDGC@3, 0.9982
2024-11-13 05:25:06,310 - root - INFO - train hit@10, 0.8970
2024-11-13 05:25:06,311 - root - INFO - validate loss: 0.1053
2024-11-13 05:25:06,311 - root - INFO - validate average_precision, 0.9938
2024-11-13 05:25:06,311 - root - INFO - validate roc_auc, 0.9935
2024-11-13 05:25:06,311 - root - INFO - validate MRR, 0.9145
2024-11-13 05:25:06,311 - root - INFO - validate NDGC@3, 1.0000
2024-11-13 05:25:06,312 - root - INFO - validate hit@10, 0.9525
2024-11-13 05:25:06,312 - root - INFO - new node validate loss: 0.2803
2024-11-13 05:25:06,312 - root - INFO - new node validate average_precision, 0.9675
2024-11-13 05:25:06,312 - root - INFO - new node validate roc_auc, 0.9650
2024-11-13 05:25:06,312 - root - INFO - new node validate MRR, 0.7380
2024-11-13 05:25:06,312 - root - INFO - new node validate NDGC@3, 0.9969
2024-11-13 05:25:06,312 - root - INFO - new node validate hit@10, 0.8165
2024-11-13 05:25:06,313 - root - INFO - save model ./saved_models/DyGFormer/Enron/DyGFormer_seed1MiniLM/DyGFormer_seed1MiniLM_1731462087.pkl
2024-11-13 05:29:00,377 - root - INFO - Epoch: 26, train for the 500-th batch, train loss: 0.12051258236169815
2024-11-13 05:32:52,231 - root - INFO - Epoch: 26, train for the 1000-th batch, train loss: 0.06909503787755966
2024-11-13 05:38:14,624 - root - INFO - Epoch: 27, train for the 500-th batch, train loss: 0.10772673040628433
2024-11-13 05:42:05,545 - root - INFO - Epoch: 27, train for the 1000-th batch, train loss: 0.035632796585559845
2024-11-13 05:47:17,905 - root - INFO - Epoch: 28, train for the 500-th batch, train loss: 0.11905752867460251
2024-11-13 05:51:11,176 - root - INFO - Epoch: 28, train for the 1000-th batch, train loss: 0.030102483928203583
2024-11-13 05:56:23,713 - root - INFO - Epoch: 29, train for the 500-th batch, train loss: 0.07985018938779831
2024-11-13 06:00:18,783 - root - INFO - Epoch: 29, train for the 1000-th batch, train loss: 0.0366029217839241
2024-11-13 06:05:29,375 - root - INFO - Epoch: 30, train for the 500-th batch, train loss: 0.11816495656967163
2024-11-13 06:09:17,582 - root - INFO - Epoch: 30, train for the 1000-th batch, train loss: 0.040093496441841125
2024-11-13 06:16:50,956 - root - INFO - Epoch: 30, learning rate: 0.0001, train loss: 0.1303
2024-11-13 06:16:50,958 - root - INFO - train average_precision, 0.9876
2024-11-13 06:16:50,958 - root - INFO - train roc_auc, 0.9877
2024-11-13 06:16:50,959 - root - INFO - train MRR, 0.8434
2024-11-13 06:16:50,959 - root - INFO - train NDGC@3, 0.9995
2024-11-13 06:16:50,959 - root - INFO - train hit@10, 0.9100
2024-11-13 06:16:50,960 - root - INFO - validate loss: 0.1032
2024-11-13 06:16:50,960 - root - INFO - validate average_precision, 0.9948
2024-11-13 06:16:50,960 - root - INFO - validate roc_auc, 0.9944
2024-11-13 06:16:50,960 - root - INFO - validate MRR, 0.9325
2024-11-13 06:16:50,960 - root - INFO - validate NDGC@3, 1.0000
2024-11-13 06:16:50,961 - root - INFO - validate hit@10, 0.9597
2024-11-13 06:16:50,961 - root - INFO - new node validate loss: 0.2839
2024-11-13 06:16:50,961 - root - INFO - new node validate average_precision, 0.9691
2024-11-13 06:16:50,961 - root - INFO - new node validate roc_auc, 0.9669
2024-11-13 06:16:50,961 - root - INFO - new node validate MRR, 0.7574
2024-11-13 06:16:50,961 - root - INFO - new node validate NDGC@3, 0.9976
2024-11-13 06:16:50,961 - root - INFO - new node validate hit@10, 0.8325
2024-11-13 06:16:50,962 - root - INFO - save model ./saved_models/DyGFormer/Enron/DyGFormer_seed1MiniLM/DyGFormer_seed1MiniLM_1731462087.pkl
2024-11-13 06:23:29,506 - root - INFO - test loss: 0.1548
2024-11-13 06:23:29,580 - root - INFO - test average_precision, 0.9932
2024-11-13 06:23:29,581 - root - INFO - test roc_auc, 0.9923
2024-11-13 06:23:29,581 - root - INFO - test MRR, 0.9215
2024-11-13 06:23:29,581 - root - INFO - test NDGC@3, 1.0000
2024-11-13 06:23:29,581 - root - INFO - test hit@10, 0.9518
2024-11-13 06:23:29,582 - root - INFO - new node test loss: 0.2681
2024-11-13 06:23:29,582 - root - INFO - new node test average_precision, 0.9757
2024-11-13 06:23:29,582 - root - INFO - new node test roc_auc, 0.9723
2024-11-13 06:23:29,582 - root - INFO - new node test MRR, 0.8038
2024-11-13 06:23:29,582 - root - INFO - new node test NDGC@3, 0.9983
2024-11-13 06:23:29,582 - root - INFO - new node test hit@10, 0.8607
2024-11-13 06:27:19,605 - root - INFO - Epoch: 31, train for the 500-th batch, train loss: 0.10075323283672333
2024-11-13 06:31:21,405 - root - INFO - Epoch: 31, train for the 1000-th batch, train loss: 0.029028475284576416
2024-11-13 06:36:42,445 - root - INFO - Epoch: 32, train for the 500-th batch, train loss: 0.099178247153759
2024-11-13 06:40:39,915 - root - INFO - Epoch: 32, train for the 1000-th batch, train loss: 0.027403593063354492
2024-11-13 06:46:01,355 - root - INFO - Epoch: 33, train for the 500-th batch, train loss: 0.10579980164766312
2024-11-13 06:49:48,990 - root - INFO - Epoch: 33, train for the 1000-th batch, train loss: 0.030004750937223434
2024-11-13 06:54:51,188 - root - INFO - Epoch: 34, train for the 500-th batch, train loss: 0.11572488397359848
2024-11-13 06:59:01,610 - root - INFO - Epoch: 34, train for the 1000-th batch, train loss: 0.03578578680753708
2024-11-13 07:04:21,950 - root - INFO - Epoch: 35, train for the 500-th batch, train loss: 0.10346008092164993
2024-11-13 07:08:27,885 - root - INFO - Epoch: 35, train for the 1000-th batch, train loss: 0.015530597418546677
2024-11-13 07:16:17,937 - root - INFO - Epoch: 35, learning rate: 0.0001, train loss: 0.1273
2024-11-13 07:16:17,939 - root - INFO - train average_precision, 0.9875
2024-11-13 07:16:17,939 - root - INFO - train roc_auc, 0.9877
2024-11-13 07:16:17,940 - root - INFO - train MRR, 0.8539
2024-11-13 07:16:17,940 - root - INFO - train NDGC@3, 0.9986
2024-11-13 07:16:17,940 - root - INFO - train hit@10, 0.9084
2024-11-13 07:16:17,941 - root - INFO - validate loss: 0.1376
2024-11-13 07:16:17,941 - root - INFO - validate average_precision, 0.9939
2024-11-13 07:16:17,941 - root - INFO - validate roc_auc, 0.9934
2024-11-13 07:16:17,941 - root - INFO - validate MRR, 0.9344
2024-11-13 07:16:17,941 - root - INFO - validate NDGC@3, 1.0000
2024-11-13 07:16:17,942 - root - INFO - validate hit@10, 0.9551
2024-11-13 07:16:17,942 - root - INFO - new node validate loss: 0.3054
2024-11-13 07:16:17,942 - root - INFO - new node validate average_precision, 0.9662
2024-11-13 07:16:17,942 - root - INFO - new node validate roc_auc, 0.9620
2024-11-13 07:16:17,942 - root - INFO - new node validate MRR, 0.7688
2024-11-13 07:16:17,942 - root - INFO - new node validate NDGC@3, 0.9962
2024-11-13 07:16:17,942 - root - INFO - new node validate hit@10, 0.8260
2024-11-13 07:20:05,343 - root - INFO - Epoch: 36, train for the 500-th batch, train loss: 0.0993475615978241
2024-11-13 07:24:00,002 - root - INFO - Epoch: 36, train for the 1000-th batch, train loss: 0.02378021366894245
2024-11-13 07:29:10,675 - root - INFO - Epoch: 37, train for the 500-th batch, train loss: 0.05712846294045448
2024-11-13 07:33:08,036 - root - INFO - Epoch: 37, train for the 1000-th batch, train loss: 0.08869572728872299
2024-11-13 07:38:35,608 - root - INFO - Epoch: 38, train for the 500-th batch, train loss: 0.10057248175144196
2024-11-13 07:42:38,596 - root - INFO - Epoch: 38, train for the 1000-th batch, train loss: 0.035434789955616
2024-11-13 07:48:03,813 - root - INFO - Epoch: 39, train for the 500-th batch, train loss: 0.09602462500333786
2024-11-13 07:52:15,241 - root - INFO - Epoch: 39, train for the 1000-th batch, train loss: 0.07703238725662231
2024-11-13 07:57:37,590 - root - INFO - Epoch: 40, train for the 500-th batch, train loss: 0.09146026521921158
2024-11-13 08:01:27,913 - root - INFO - Epoch: 40, train for the 1000-th batch, train loss: 0.1164015457034111
2024-11-13 08:09:08,917 - root - INFO - Epoch: 40, learning rate: 0.0001, train loss: 0.1178
2024-11-13 08:09:08,955 - root - INFO - train average_precision, 0.9886
2024-11-13 08:09:08,956 - root - INFO - train roc_auc, 0.9890
2024-11-13 08:09:08,956 - root - INFO - train MRR, 0.8530
2024-11-13 08:09:08,957 - root - INFO - train NDGC@3, 0.9995
2024-11-13 08:09:08,957 - root - INFO - train hit@10, 0.9108
2024-11-13 08:09:08,957 - root - INFO - validate loss: 0.1351
2024-11-13 08:09:08,958 - root - INFO - validate average_precision, 0.9940
2024-11-13 08:09:08,958 - root - INFO - validate roc_auc, 0.9935
2024-11-13 08:09:08,958 - root - INFO - validate MRR, 0.9387
2024-11-13 08:09:08,958 - root - INFO - validate NDGC@3, 1.0000
2024-11-13 08:09:08,958 - root - INFO - validate hit@10, 0.9594
2024-11-13 08:09:08,958 - root - INFO - new node validate loss: 0.3097
2024-11-13 08:09:08,959 - root - INFO - new node validate average_precision, 0.9677
2024-11-13 08:09:08,959 - root - INFO - new node validate roc_auc, 0.9637
2024-11-13 08:09:08,959 - root - INFO - new node validate MRR, 0.7781
2024-11-13 08:09:08,959 - root - INFO - new node validate NDGC@3, 0.9991
2024-11-13 08:09:08,959 - root - INFO - new node validate hit@10, 0.8429
2024-11-13 08:15:37,446 - root - INFO - test loss: 0.1919
2024-11-13 08:15:37,448 - root - INFO - test average_precision, 0.9954
2024-11-13 08:15:37,449 - root - INFO - test roc_auc, 0.9948
2024-11-13 08:15:37,449 - root - INFO - test MRR, 0.9531
2024-11-13 08:15:37,449 - root - INFO - test NDGC@3, 1.0000
2024-11-13 08:15:37,449 - root - INFO - test hit@10, 0.9663
2024-11-13 08:15:37,450 - root - INFO - new node test loss: 0.3212
2024-11-13 08:15:37,450 - root - INFO - new node test average_precision, 0.9799
2024-11-13 08:15:37,450 - root - INFO - new node test roc_auc, 0.9769
2024-11-13 08:15:37,450 - root - INFO - new node test MRR, 0.8482
2024-11-13 08:15:37,450 - root - INFO - new node test NDGC@3, 0.9983
2024-11-13 08:15:37,450 - root - INFO - new node test hit@10, 0.8889
2024-11-13 08:19:21,059 - root - INFO - Epoch: 41, train for the 500-th batch, train loss: 0.1346583217382431
2024-11-13 08:23:29,035 - root - INFO - Epoch: 41, train for the 1000-th batch, train loss: 0.07012823224067688
2024-11-13 08:28:52,637 - root - INFO - Epoch: 42, train for the 500-th batch, train loss: 0.09532035887241364
2024-11-13 08:32:52,834 - root - INFO - Epoch: 42, train for the 1000-th batch, train loss: 0.08221004158258438
2024-11-13 08:38:14,142 - root - INFO - Epoch: 43, train for the 500-th batch, train loss: 0.0913836658000946
2024-11-13 08:41:36,436 - root - INFO - Epoch: 43, train for the 1000-th batch, train loss: 0.015981752425432205
2024-11-13 08:45:03,289 - root - INFO - Epoch: 44, train for the 500-th batch, train loss: 0.04843053221702576
2024-11-13 08:47:37,722 - root - INFO - Epoch: 44, train for the 1000-th batch, train loss: 0.027051016688346863
2024-11-13 08:51:02,846 - root - INFO - Epoch: 45, train for the 500-th batch, train loss: 0.08558465540409088
2024-11-13 08:53:36,454 - root - INFO - Epoch: 45, train for the 1000-th batch, train loss: 0.0717969685792923
2024-11-13 08:58:30,180 - root - INFO - Epoch: 45, learning rate: 0.0001, train loss: 0.1100
2024-11-13 08:58:30,181 - root - INFO - train average_precision, 0.9898
2024-11-13 08:58:30,181 - root - INFO - train roc_auc, 0.9904
2024-11-13 08:58:30,182 - root - INFO - train MRR, 0.8680
2024-11-13 08:58:30,182 - root - INFO - train NDGC@3, 0.9992
2024-11-13 08:58:30,183 - root - INFO - train hit@10, 0.9218
2024-11-13 08:58:30,183 - root - INFO - validate loss: 0.1187
2024-11-13 08:58:30,183 - root - INFO - validate average_precision, 0.9943
2024-11-13 08:58:30,183 - root - INFO - validate roc_auc, 0.9937
2024-11-13 08:58:30,183 - root - INFO - validate MRR, 0.9379
2024-11-13 08:58:30,184 - root - INFO - validate NDGC@3, 0.9996
2024-11-13 08:58:30,184 - root - INFO - validate hit@10, 0.9575
2024-11-13 08:58:30,184 - root - INFO - new node validate loss: 0.3505
2024-11-13 08:58:30,184 - root - INFO - new node validate average_precision, 0.9692
2024-11-13 08:58:30,184 - root - INFO - new node validate roc_auc, 0.9662
2024-11-13 08:58:30,184 - root - INFO - new node validate MRR, 0.7786
2024-11-13 08:58:30,184 - root - INFO - new node validate NDGC@3, 0.9962
2024-11-13 08:58:30,185 - root - INFO - new node validate hit@10, 0.8374
2024-11-13 09:01:00,269 - root - INFO - Epoch: 46, train for the 500-th batch, train loss: 0.08329641819000244
2024-11-13 09:03:36,464 - root - INFO - Epoch: 46, train for the 1000-th batch, train loss: 0.11590544879436493
2024-11-13 09:07:03,784 - root - INFO - Epoch: 47, train for the 500-th batch, train loss: 0.0709715485572815
2024-11-13 09:09:41,483 - root - INFO - Epoch: 47, train for the 1000-th batch, train loss: 0.03917575627565384
2024-11-13 09:13:06,973 - root - INFO - Epoch: 48, train for the 500-th batch, train loss: 0.07456186413764954
2024-11-13 09:15:42,442 - root - INFO - Epoch: 48, train for the 1000-th batch, train loss: 0.01980808563530445
2024-11-13 09:19:06,190 - root - INFO - Epoch: 49, train for the 500-th batch, train loss: 0.09103941172361374
2024-11-13 09:21:38,754 - root - INFO - Epoch: 49, train for the 1000-th batch, train loss: 0.023833848536014557
2024-11-13 09:25:06,237 - root - INFO - Epoch: 50, train for the 500-th batch, train loss: 0.10364565998315811
2024-11-13 09:27:41,229 - root - INFO - Epoch: 50, train for the 1000-th batch, train loss: 0.024052944034337997
2024-11-13 09:32:40,810 - root - INFO - Epoch: 50, learning rate: 0.0001, train loss: 0.1079
2024-11-13 09:32:40,811 - root - INFO - train average_precision, 0.9900
2024-11-13 09:32:40,812 - root - INFO - train roc_auc, 0.9905
2024-11-13 09:32:40,812 - root - INFO - train MRR, 0.8685
2024-11-13 09:32:40,813 - root - INFO - train NDGC@3, 0.9995
2024-11-13 09:32:40,813 - root - INFO - train hit@10, 0.9228
2024-11-13 09:32:40,813 - root - INFO - validate loss: 0.1672
2024-11-13 09:32:40,813 - root - INFO - validate average_precision, 0.9935
2024-11-13 09:32:40,814 - root - INFO - validate roc_auc, 0.9928
2024-11-13 09:32:40,814 - root - INFO - validate MRR, 0.9340
2024-11-13 09:32:40,814 - root - INFO - validate NDGC@3, 0.9996
2024-11-13 09:32:40,814 - root - INFO - validate hit@10, 0.9550
2024-11-13 09:32:40,814 - root - INFO - new node validate loss: 0.3752
2024-11-13 09:32:40,814 - root - INFO - new node validate average_precision, 0.9644
2024-11-13 09:32:40,815 - root - INFO - new node validate roc_auc, 0.9596
2024-11-13 09:32:40,815 - root - INFO - new node validate MRR, 0.7557
2024-11-13 09:32:40,815 - root - INFO - new node validate NDGC@3, 0.9993
2024-11-13 09:32:40,815 - root - INFO - new node validate hit@10, 0.8276
2024-11-13 09:36:42,879 - root - INFO - test loss: 0.2118
2024-11-13 09:36:42,883 - root - INFO - test average_precision, 0.9943
2024-11-13 09:36:42,883 - root - INFO - test roc_auc, 0.9935
2024-11-13 09:36:42,884 - root - INFO - test MRR, 0.9445
2024-11-13 09:36:42,884 - root - INFO - test NDGC@3, 1.0000
2024-11-13 09:36:42,884 - root - INFO - test hit@10, 0.9612
2024-11-13 09:36:42,884 - root - INFO - new node test loss: 0.3555
2024-11-13 09:36:42,884 - root - INFO - new node test average_precision, 0.9763
2024-11-13 09:36:42,884 - root - INFO - new node test roc_auc, 0.9727
2024-11-13 09:36:42,884 - root - INFO - new node test MRR, 0.8303
2024-11-13 09:36:42,885 - root - INFO - new node test NDGC@3, 0.9976
2024-11-13 09:36:42,885 - root - INFO - new node test hit@10, 0.8726
2024-11-13 09:36:42,885 - root - INFO - load model ./saved_models/DyGFormer/Enron/DyGFormer_seed1MiniLM/DyGFormer_seed1MiniLM_1731462087.pkl
2024-11-13 09:36:42,905 - root - INFO - get final performance on dataset Enron...
2024-11-13 09:44:45,907 - root - INFO - validate loss: 0.1032
2024-11-13 09:44:45,930 - root - INFO - validate average_precision, 0.9948
2024-11-13 09:44:45,930 - root - INFO - validate roc_auc, 0.9944
2024-11-13 09:44:45,931 - root - INFO - validate MRR, 0.9325
2024-11-13 09:44:45,931 - root - INFO - validate NDGC@3, 1.0000
2024-11-13 09:44:45,931 - root - INFO - validate hit@10, 0.9597
2024-11-13 09:44:45,931 - root - INFO - new node validate loss: 0.2839
2024-11-13 09:44:45,932 - root - INFO - new node validate average_precision, 0.9691
2024-11-13 09:44:45,932 - root - INFO - new node validate roc_auc, 0.9669
2024-11-13 09:44:45,932 - root - INFO - new node validate MRR, 0.7574
2024-11-13 09:44:45,932 - root - INFO - new node validate NDGC@3, 0.9976
2024-11-13 09:44:45,932 - root - INFO - new node validate hit@10, 0.8325
2024-11-13 09:44:45,932 - root - INFO - test loss: 0.1548
2024-11-13 09:44:45,932 - root - INFO - test average_precision, 0.9932
2024-11-13 09:44:45,933 - root - INFO - test roc_auc, 0.9923
2024-11-13 09:44:45,933 - root - INFO - test MRR, 0.9215
2024-11-13 09:44:45,933 - root - INFO - test NDGC@3, 1.0000
2024-11-13 09:44:45,933 - root - INFO - test hit@10, 0.9518
2024-11-13 09:44:45,933 - root - INFO - new node test loss: 0.2681
2024-11-13 09:44:45,934 - root - INFO - new node test average_precision, 0.9757
2024-11-13 09:44:45,934 - root - INFO - new node test roc_auc, 0.9723
2024-11-13 09:44:45,934 - root - INFO - new node test MRR, 0.8038
2024-11-13 09:44:45,934 - root - INFO - new node test NDGC@3, 0.9983
2024-11-13 09:44:45,934 - root - INFO - new node test hit@10, 0.8607
2024-11-13 09:44:45,934 - root - INFO - Run 2 cost 28998.79 seconds.
